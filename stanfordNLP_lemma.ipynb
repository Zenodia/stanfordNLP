{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stanfordnlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the default treebank \"sv_talbanken\" for language \"sv\".\n",
      "Would you like to download the models for: sv_talbanken now? (Y/n)\n",
      "Y\n",
      "\n",
      "Default download directory: C:\\Users\\zecharpy\\stanfordnlp_resources\n",
      "Hit enter to continue or type an alternate directory.\n",
      "C:\\Users\\zecharpy\\Desktop\\stanfordNLP\n",
      "\n",
      "Downloading models for: sv_talbanken\n",
      "Download location: C:\\Users\\zecharpy\\Desktop\\stanfordNLP\\sv_talbanken_models.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 225M/225M [01:08<00:00, 2.84MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Download complete.  Models saved to: C:\\Users\\zecharpy\\Desktop\\stanfordNLP\\sv_talbanken_models.zip\n",
      "Extracting models file for: sv_talbanken\n",
      "Cleaning up...Done.\n"
     ]
    }
   ],
   "source": [
    "modelpath='C:\\Users\\zecharpy\\Desktop\\stanfordNLP\\sv_talbanken'\n",
    "language='sv'\n",
    "stanfordnlp.download('sv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use device: cpu\n",
      "---\n",
      "Loading: tokenize\n",
      "With settings: \n",
      "{'model_path': '.\\\\sv_talbanken_models\\\\sv_talbanken_tokenizer.pt', 'lang': 'sv', 'shorthand': 'sv_talbanken', 'mode': 'predict'}\n",
      "---\n",
      "Loading: pos\n",
      "With settings: \n",
      "{'model_path': '.\\\\sv_talbanken_models\\\\sv_talbanken_tagger.pt', 'pretrain_path': '.\\\\sv_talbanken_models\\\\sv_talbanken.pretrain.pt', 'lang': 'sv', 'shorthand': 'sv_talbanken', 'mode': 'predict'}\n",
      "---\n",
      "Loading: lemma\n",
      "With settings: \n",
      "{'model_path': '.\\\\sv_talbanken_models\\\\sv_talbanken_lemmatizer.pt', 'lang': 'sv', 'shorthand': 'sv_talbanken', 'mode': 'predict'}\n",
      "Building an attentional Seq2Seq model...\n",
      "Using a Bi-LSTM encoder\n",
      "Using soft attention for LSTM.\n",
      "Finetune all embeddings.\n",
      "[Running seq2seq lemmatizer with edit classifier]\n",
      "---\n",
      "Loading: depparse\n",
      "With settings: \n",
      "{'model_path': '.\\\\sv_talbanken_models\\\\sv_talbanken_parser.pt', 'pretrain_path': '.\\\\sv_talbanken_models\\\\sv_talbanken.pretrain.pt', 'lang': 'sv', 'shorthand': 'sv_talbanken', 'mode': 'predict'}\n",
      "Done loading processors!\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "pipeline = stanfordnlp.Pipeline(models_dir='.', lang='sv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use device: cpu\n",
      "---\n",
      "Loading: tokenize\n",
      "With settings: \n",
      "{'model_path': '.\\\\sv_talbanken_models\\\\sv_talbanken_tokenizer.pt', 'lang': 'sv', 'shorthand': 'sv_talbanken', 'mode': 'predict'}\n",
      "---\n",
      "Loading: pos\n",
      "With settings: \n",
      "{'model_path': '.\\\\sv_talbanken_models\\\\sv_talbanken_tagger.pt', 'pretrain_path': '.\\\\sv_talbanken_models\\\\sv_talbanken.pretrain.pt', 'lang': 'sv', 'shorthand': 'sv_talbanken', 'mode': 'predict'}\n",
      "---\n",
      "Loading: lemma\n",
      "With settings: \n",
      "{'model_path': '.\\\\sv_talbanken_models\\\\sv_talbanken_lemmatizer.pt', 'lang': 'sv', 'shorthand': 'sv_talbanken', 'mode': 'predict'}\n",
      "Building an attentional Seq2Seq model...\n",
      "Using a Bi-LSTM encoder\n",
      "Using soft attention for LSTM.\n",
      "Finetune all embeddings.\n",
      "[Running seq2seq lemmatizer with edit classifier]\n",
      "Done loading processors!\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "nlp = stanfordnlp.Pipeline(models_dir='.', lang='sv',processors='tokenize,mwt,pos,lemma')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sentence --- \n",
      "\n",
      "En man ska ha blivit påkörd av en buss vid Södra torget i Borås . Polis och ambulans har larmats till platsen . Mannen har förts till sjukhus .\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"En man ska ha blivit påkörd av en buss vid Södra torget i Borås. Polis och ambulans har larmats till platsen. Mannen har förts till sjukhus.\")\n",
    "doc.sentences[0].print_dependencies()\n",
    "print('Original sentence --- \\n')\n",
    "print(' '.join([word.text for sent in doc.sentences for word in sent.words]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extract name entiry from original sentence: \n",
      "\n",
      "word: En \t POS: DET \t feat:Definite=Ind|Gender=Com|Number=Sing|PronType=Art\n",
      "word: man \t POS: NOUN \t feat:Case=Nom|Definite=Ind|Gender=Com|Number=Sing\n",
      "word: ska \t POS: AUX \t feat:Mood=Ind|Tense=Pres|VerbForm=Fin|Voice=Act\n",
      "word: ha \t POS: AUX \t feat:VerbForm=Inf|Voice=Act\n",
      "word: blivit \t POS: AUX \t feat:VerbForm=Sup|Voice=Act\n",
      "word: påkörd \t POS: VERB \t feat:Case=Nom|Definite=Ind|Gender=Com|Number=Sing|Tense=Past|VerbForm=Part\n",
      "word: av \t POS: ADP \t feat:_\n",
      "word: en \t POS: DET \t feat:Definite=Ind|Gender=Com|Number=Sing|PronType=Art\n",
      "word: buss \t POS: NOUN \t feat:Case=Nom|Definite=Ind|Gender=Com|Number=Sing\n",
      "word: vid \t POS: ADP \t feat:_\n",
      "word: Södra \t POS: ADJ \t feat:Case=Nom|Definite=Def|Degree=Pos|Number=Sing\n",
      "word: torget \t POS: NOUN \t feat:Case=Nom|Definite=Def|Gender=Neut|Number=Sing\n",
      "word: i \t POS: ADP \t feat:_\n",
      "word: Borås \t POS: PROPN \t feat:Case=Nom\n",
      "word: . \t POS: PUNCT \t feat:_\n",
      "word: Polis \t POS: NOUN \t feat:Case=Nom|Definite=Ind|Gender=Com|Number=Sing\n",
      "word: och \t POS: CCONJ \t feat:_\n",
      "word: ambulans \t POS: NOUN \t feat:Case=Nom|Definite=Ind|Gender=Com|Number=Sing\n",
      "word: har \t POS: AUX \t feat:Mood=Ind|Tense=Pres|VerbForm=Fin|Voice=Act\n",
      "word: larmats \t POS: VERB \t feat:VerbForm=Sup|Voice=Pass\n",
      "word: till \t POS: ADP \t feat:_\n",
      "word: platsen \t POS: NOUN \t feat:Case=Nom|Definite=Def|Gender=Com|Number=Sing\n",
      "word: . \t POS: PUNCT \t feat:_\n",
      "word: Mannen \t POS: NOUN \t feat:Case=Nom|Definite=Def|Gender=Com|Number=Sing\n",
      "word: har \t POS: AUX \t feat:Mood=Ind|Tense=Pres|VerbForm=Fin|Voice=Act\n",
      "word: förts \t POS: VERB \t feat:VerbForm=Sup|Voice=Pass\n",
      "word: till \t POS: ADP \t feat:_\n",
      "word: sjukhus \t POS: NOUN \t feat:Case=Nom|Definite=Ind|Gender=Neut|Number=Sing\n",
      "word: . \t POS: PUNCT \t feat:_\n"
     ]
    }
   ],
   "source": [
    "print('extract name entiry from original sentence: \\n')\n",
    "print(*[f'word: {word.text+\" \"}\\t POS: {word.upos} \\t feat:{word.feats}' for sent in doc.sentences for word in sent.words], sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word: Hur \tname_entity: ADV \t feat:_\n",
      "word: funka \tname_entity: VERB \t feat:VerbForm=Inf|Voice=Act\n",
      "word: database \tname_entity: NOUN \t feat:Case=Nom|Definite=Ind|Gender=Com|Number=Sing\n",
      "word: ? \tname_entity: PUNCT \t feat:_\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Hur funka database ?\")\n",
    "doc.sentences[0].print_dependencies()\n",
    "\n",
    "print(*[f'word: {word.text+\" \"}\\tname_entity: {word.upos} \\t feat:{word.feats}' for sent in doc.sentences for word in sent.words], sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting lemma from original sentence \n",
      "\n",
      "word: En \tlemma: en\n",
      "word: man \tlemma: man\n",
      "word: ska \tlemma: skola\n",
      "word: ha \tlemma: ha\n",
      "word: blivit \tlemma: bli\n",
      "word: påkörd \tlemma: påkörd\n",
      "word: av \tlemma: av\n",
      "word: en \tlemma: en\n",
      "word: buss \tlemma: buss\n",
      "word: vid \tlemma: vid\n",
      "word: Södra \tlemma: södra\n",
      "word: torget \tlemma: torg\n",
      "word: i \tlemma: i\n",
      "word: Borås \tlemma: Borås\n",
      "word: . \tlemma: .\n",
      "word: Polis \tlemma: Polis\n",
      "word: och \tlemma: och\n",
      "word: ambulans \tlemma: ambulans\n",
      "word: har \tlemma: ha\n",
      "word: larmats \tlemma: larmat\n",
      "word: till \tlemma: till\n",
      "word: platsen \tlemma: plats\n",
      "word: . \tlemma: .\n",
      "word: Mannen \tlemma: man\n",
      "word: har \tlemma: ha\n",
      "word: förts \tlemma: föra\n",
      "word: till \tlemma: till\n",
      "word: sjukhus \tlemma: sjukhus\n",
      "word: . \tlemma: .\n"
     ]
    }
   ],
   "source": [
    "print('extracting lemma from original sentence \\n')\n",
    "print(*[f'word: {word.text+\" \"}\\tlemma: {word.lemma}' for sent in doc.sentences for word in sent.words], sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token: En       \t\twords: [<Word index=1;text=En;lemma=en;upos=DET;xpos=DT|UTR|SIN|IND;feats=Definite=Ind|Gender=Com|Number=Sing|PronType=Art>]\n",
      "token: man      \t\twords: [<Word index=2;text=man;lemma=man;upos=NOUN;xpos=NN|UTR|SIN|IND|NOM;feats=Case=Nom|Definite=Ind|Gender=Com|Number=Sing>]\n",
      "token: ska      \t\twords: [<Word index=3;text=ska;lemma=skola;upos=AUX;xpos=VB|PRS|AKT;feats=Mood=Ind|Tense=Pres|VerbForm=Fin|Voice=Act>]\n",
      "token: ha       \t\twords: [<Word index=4;text=ha;lemma=ha;upos=AUX;xpos=VB|INF|AKT;feats=VerbForm=Inf|Voice=Act>]\n",
      "token: blivit   \t\twords: [<Word index=5;text=blivit;lemma=bli;upos=AUX;xpos=VB|SUP|AKT;feats=VerbForm=Sup|Voice=Act>]\n",
      "token: påkörd   \t\twords: [<Word index=6;text=påkörd;lemma=påkörd;upos=VERB;xpos=PC|PRF|UTR|SIN|IND|NOM;feats=Case=Nom|Definite=Ind|Gender=Com|Number=Sing|Tense=Past|VerbForm=Part>]\n",
      "token: av       \t\twords: [<Word index=7;text=av;lemma=av;upos=ADP;xpos=PP;feats=_>]\n",
      "token: en       \t\twords: [<Word index=8;text=en;lemma=en;upos=DET;xpos=DT|UTR|SIN|IND;feats=Definite=Ind|Gender=Com|Number=Sing|PronType=Art>]\n",
      "token: buss     \t\twords: [<Word index=9;text=buss;lemma=buss;upos=NOUN;xpos=NN|UTR|SIN|IND|NOM;feats=Case=Nom|Definite=Ind|Gender=Com|Number=Sing>]\n",
      "token: vid      \t\twords: [<Word index=10;text=vid;lemma=vid;upos=ADP;xpos=PP;feats=_>]\n",
      "token: Södra    \t\twords: [<Word index=11;text=Södra;lemma=södra;upos=ADJ;xpos=JJ|POS|UTR/NEU|SIN|DEF|NOM;feats=Case=Nom|Definite=Def|Degree=Pos|Number=Sing>]\n",
      "token: torget   \t\twords: [<Word index=12;text=torget;lemma=torg;upos=NOUN;xpos=NN|NEU|SIN|DEF|NOM;feats=Case=Nom|Definite=Def|Gender=Neut|Number=Sing>]\n",
      "token: i        \t\twords: [<Word index=13;text=i;lemma=i;upos=ADP;xpos=PP;feats=_>]\n",
      "token: Borås    \t\twords: [<Word index=14;text=Borås;lemma=Borås;upos=PROPN;xpos=PM|NOM;feats=Case=Nom>]\n",
      "token: .        \t\twords: [<Word index=15;text=.;lemma=.;upos=PUNCT;xpos=MAD;feats=_>]\n",
      "token: Polis    \t\twords: [<Word index=1;text=Polis;lemma=Polis;upos=NOUN;xpos=NN|UTR|SIN|IND|NOM;feats=Case=Nom|Definite=Ind|Gender=Com|Number=Sing>]\n",
      "token: och      \t\twords: [<Word index=2;text=och;lemma=och;upos=CCONJ;xpos=KN;feats=_>]\n",
      "token: ambulans \t\twords: [<Word index=3;text=ambulans;lemma=ambulans;upos=NOUN;xpos=NN|UTR|SIN|IND|NOM;feats=Case=Nom|Definite=Ind|Gender=Com|Number=Sing>]\n",
      "token: har      \t\twords: [<Word index=4;text=har;lemma=ha;upos=AUX;xpos=VB|PRS|AKT;feats=Mood=Ind|Tense=Pres|VerbForm=Fin|Voice=Act>]\n",
      "token: larmats  \t\twords: [<Word index=5;text=larmats;lemma=larmat;upos=VERB;xpos=VB|SUP|SFO;feats=VerbForm=Sup|Voice=Pass>]\n",
      "token: till     \t\twords: [<Word index=6;text=till;lemma=till;upos=ADP;xpos=PP;feats=_>]\n",
      "token: platsen  \t\twords: [<Word index=7;text=platsen;lemma=plats;upos=NOUN;xpos=NN|UTR|SIN|DEF|NOM;feats=Case=Nom|Definite=Def|Gender=Com|Number=Sing>]\n",
      "token: .        \t\twords: [<Word index=8;text=.;lemma=.;upos=PUNCT;xpos=MAD;feats=_>]\n",
      "token: Mannen   \t\twords: [<Word index=1;text=Mannen;lemma=man;upos=NOUN;xpos=NN|UTR|SIN|DEF|NOM;feats=Case=Nom|Definite=Def|Gender=Com|Number=Sing>]\n",
      "token: har      \t\twords: [<Word index=2;text=har;lemma=ha;upos=AUX;xpos=VB|PRS|AKT;feats=Mood=Ind|Tense=Pres|VerbForm=Fin|Voice=Act>]\n",
      "token: förts    \t\twords: [<Word index=3;text=förts;lemma=föra;upos=VERB;xpos=VB|SUP|SFO;feats=VerbForm=Sup|Voice=Pass>]\n",
      "token: till     \t\twords: [<Word index=4;text=till;lemma=till;upos=ADP;xpos=PP;feats=_>]\n",
      "token: sjukhus  \t\twords: [<Word index=5;text=sjukhus;lemma=sjukhus;upos=NOUN;xpos=NN|NEU|SIN|IND|NOM;feats=Case=Nom|Definite=Ind|Gender=Neut|Number=Sing>]\n",
      "token: .        \t\twords: [<Word index=6;text=.;lemma=.;upos=PUNCT;xpos=MAD;feats=_>]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(*[f'token: {token.text.ljust(9)}\\t\\twords: {token.words}' for sent in doc.sentences for token in sent.tokens], sep='\\n')\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word: En       \t\ttoken parent:1-En\n",
      "word: man      \t\ttoken parent:2-man\n",
      "word: ska      \t\ttoken parent:3-ska\n",
      "word: ha       \t\ttoken parent:4-ha\n",
      "word: blivit   \t\ttoken parent:5-blivit\n",
      "word: påkörd   \t\ttoken parent:6-påkörd\n",
      "word: av       \t\ttoken parent:7-av\n",
      "word: en       \t\ttoken parent:8-en\n",
      "word: buss     \t\ttoken parent:9-buss\n",
      "word: vid      \t\ttoken parent:10-vid\n",
      "word: Södra    \t\ttoken parent:11-Södra\n",
      "word: torget   \t\ttoken parent:12-torget\n",
      "word: i        \t\ttoken parent:13-i\n",
      "word: Borås    \t\ttoken parent:14-Borås\n",
      "word: .        \t\ttoken parent:15-.\n",
      "word: Polis    \t\ttoken parent:1-Polis\n",
      "word: och      \t\ttoken parent:2-och\n",
      "word: ambulans \t\ttoken parent:3-ambulans\n",
      "word: har      \t\ttoken parent:4-har\n",
      "word: larmats  \t\ttoken parent:5-larmats\n",
      "word: till     \t\ttoken parent:6-till\n",
      "word: platsen  \t\ttoken parent:7-platsen\n",
      "word: .        \t\ttoken parent:8-.\n",
      "word: Mannen   \t\ttoken parent:1-Mannen\n",
      "word: har      \t\ttoken parent:2-har\n",
      "word: förts    \t\ttoken parent:3-förts\n",
      "word: till     \t\ttoken parent:4-till\n",
      "word: sjukhus  \t\ttoken parent:5-sjukhus\n",
      "word: .        \t\ttoken parent:6-.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(*[f'word: {word.text.ljust(9)}\\t\\ttoken parent:{word.parent_token.index+\"-\"+word.parent_token.text}' for sent in doc.sentences for word in sent.words], sep='\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
